{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# print('当前工作目录:', os.getcwd())\n",
    "ocr_types_dict = {\n",
    "    'drawings_text_ocr': 'drawings_text_ocr'\n",
    "}\n",
    "\n",
    "result_folder = '../result'\n",
    "\n",
    "# match_name = 'quick_match'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall result: not distinguishing between Chinese and English, page-level average\n",
    "# 整体评测结果统计\n",
    "# 读取各 OCR 结果 JSON，提取文本块、公式、表格、阅读顺序等多项指标，计算整体分数（overall），并输出为 DataFrame。\n",
    "\n",
    "dict_list = []\n",
    "\n",
    "for ocr_type in ocr_types_dict.values():\n",
    "    # result_path = os.path.join(result_folder, f'{ocr_type}_{match_name}_metric_result.json')\n",
    "    result_path = os.path.join(result_folder, f'{ocr_type}_metric_result.json')\n",
    "\n",
    "    with open(result_path, 'r') as f:\n",
    "        result = json.load(f)\n",
    "    \n",
    "    save_dict = {}\n",
    "\n",
    "    for category_type, metric in [(\"text_block\", \"Edit_dist\"), (\"display_formula\", \"CDM\"), (\"table\", \"TEDS\"), (\"table\", \"TEDS_structure_only\"), (\"reading_order\", \"Edit_dist\")]:\n",
    "        if metric == 'CDM' or metric == \"TEDS\" or metric == \"TEDS_structure_only\":\n",
    "            if result[category_type][\"page\"].get(metric):\n",
    "                save_dict[category_type+'_'+metric] = result[category_type][\"page\"][metric][\"ALL\"] * 100   # page级别的avg\n",
    "            else:\n",
    "                save_dict[category_type+'_'+metric] = 0\n",
    "        else:\n",
    "            save_dict[category_type+'_'+metric] = result[category_type][\"all\"][metric].get(\"ALL_page_avg\", np.nan)\n",
    "\n",
    "    dict_list.append(save_dict)\n",
    "    \n",
    "df = pd.DataFrame(dict_list, index=ocr_types_dict.keys()).round(3)\n",
    "df['overall'] = ((1-df['text_block_Edit_dist'])*100 + df['display_formula_CDM'] + df['table_TEDS'])/3\n",
    "# df.to_csv('./overall.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF type\n",
    "# 按 PDF 来源类型统计\n",
    "# 统计不同 PDF 来源（如教材、PPT、报告、杂志等）下的文本块编辑距离表现，输出各来源及均值的 DataFrame。\n",
    "dict_list = []\n",
    "\n",
    "for ocr_type in ocr_types_dict.values():\n",
    "    result_path = os.path.join(result_folder, f'{ocr_type}_{match_name}_metric_result.json')\n",
    "    \n",
    "    with open(result_path, 'r') as f:\n",
    "        result = json.load(f)\n",
    "    \n",
    "    # for category_type in result.keys():\n",
    "    dict_list.append(result['text_block'][\"page\"][\"Edit_dist\"])\n",
    "df2 = pd.DataFrame(dict_list, index=ocr_types_dict.keys())\n",
    "\n",
    "reordered_df2 = df2.round(3)\n",
    "\n",
    "selected_columns = reordered_df2[[\"data_source: book\", \"data_source: PPT2PDF\", \"data_source: research_report\", \"data_source: colorful_textbook\", \"data_source: exam_paper\", \"data_source: magazine\", \"data_source: academic_literature\", \"data_source: note\", \"data_source: newspaper\"]]\n",
    "# calculate mean\n",
    "selected_columns['mean'] = reordered_df2[\"ALL\"]\n",
    "# selected_columns['variance'] = selected_columns.var(axis=1)\n",
    "# selected_columns.to_csv('./data_source.csv')\n",
    "\n",
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# page special issue\n",
    "# 页面特殊问题统计\n",
    "# 统计如“模糊扫描”“水印”“彩色背景”等特殊页面情况下的文本块编辑距离表现，输出相关 DataFrame\n",
    "dict_list = []\n",
    "\n",
    "for ocr_type in ocr_types_dict.values():\n",
    "    result_path = os.path.join(result_folder, f'{ocr_type}_{match_name}_metric_result.json')\n",
    "    \n",
    "    with open(result_path, 'r') as f:\n",
    "        result = json.load(f)\n",
    "    \n",
    "    # for category_type in result.keys():\n",
    "    dict_list.append(result['text_block'][\"page\"][\"Edit_dist\"])\n",
    "df2 = pd.DataFrame(dict_list, index=ocr_types_dict.keys())\n",
    "\n",
    "reordered_df2 = df2.round(3)\n",
    "reordered_df2\n",
    "\n",
    "# selected_columns = reordered_df2[['fuzzy_scan', 'watermark', 'colorful_backgroud']] # use this for full dataset\n",
    "selected_columns = reordered_df2[[col for col in ['fuzzy_scan', 'watermark', 'colorful_backgroud'] if col in reordered_df2.columns]]\n",
    "\n",
    "# selected_columns.to_csv('./page_issue.csv')\n",
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading order under different layout\n",
    "# 不同版面布局下阅读顺序统计\n",
    "# 统计单栏、双栏、三栏、其他布局下的阅读顺序编辑距离表现，输出相关 DataFrame。\n",
    "dict_list = []\n",
    "\n",
    "for ocr_type in ocr_types_dict.values():\n",
    "    result_path = os.path.join(result_folder, f'{ocr_type}_{match_name}_metric_result.json')\n",
    "    \n",
    "    with open(result_path, 'r') as f:\n",
    "        result = json.load(f)\n",
    "    \n",
    "    # for category_type in result.keys():\n",
    "    dict_list.append(result['reading_order'][\"page\"][\"Edit_dist\"])\n",
    "\n",
    "df3 = pd.DataFrame(dict_list, index=ocr_types_dict.keys())\n",
    "\n",
    "reordered_df3 = df3.round(3)\n",
    "\n",
    "\n",
    "selected_columns3 = reordered_df3[[\"layout: single_column\", \"layout: double_column\", \"layout: three_column\", \"layout: other_layout\"]]\n",
    "\n",
    "# selected_columns3.to_csv('./layout.csv')\n",
    "selected_columns3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text attribute\n",
    "# 文本属性统计\n",
    "# 统计不同文本语言、背景色等属性下的文本块编辑距离表现，输出相关 DataFrame。\n",
    "dict_list = []\n",
    "\n",
    "for ocr_type in ocr_types_dict.values():\n",
    "    result_path = os.path.join(result_folder, f'{ocr_type}_{match_name}_metric_result.json')\n",
    "    \n",
    "    with open(result_path, 'r') as f:\n",
    "        result = json.load(f)\n",
    "    \n",
    "    # for category_type in result.keys():\n",
    "    dict_list.append(result['text_block'][\"group\"][\"Edit_dist\"])\n",
    "\n",
    "df4 = pd.DataFrame(dict_list, index=ocr_types_dict.keys())\n",
    "df4 = df4.round(3)\n",
    "\n",
    "selected_columns = df4[[\"text_language: text_english\", \"text_language: text_simplified_chinese\", \"text_language: text_en_ch_mixed\", \"text_background: white\", \"text_background: single_colored\", \"text_background: multi_colored\"]]\n",
    "\n",
    "# selected_columns.to_csv('.text_attribute.csv')\n",
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table attribute\n",
    "# 表格属性统计\n",
    "# 统计不同表格语言、线条、是否含公式/背景、布局等属性下的 TEDS 指标表现，输出相关 DataFrame。\n",
    "dict_list = []\n",
    "\n",
    "for ocr_type in ocr_types_dict.values():\n",
    "    result_path = os.path.join(result_folder, f'{ocr_type}_{match_name}_metric_result.json')\n",
    "    \n",
    "    with open(result_path, 'r') as f:\n",
    "        result = json.load(f)\n",
    "    \n",
    "    # for category_type in result.keys():\n",
    "    dict_list.append(result['table'][\"group\"][\"TEDS\"])\n",
    "\n",
    "df4 = pd.DataFrame(dict_list, index=ocr_types_dict.keys())\n",
    "df4 = df4 * 100\n",
    "df4 = df4.round(1)\n",
    "\n",
    "selected_columns = df4[[col for col in [\n",
    "    \"language: table_en\", \n",
    "    \"language: table_simplified_chinese\", \n",
    "    \"language: table_en_ch_mixed\", \n",
    "    \"line: full_line\", \n",
    "    \"line: less_line\", \n",
    "    \"line: fewer_line\", \n",
    "    \"line: wireless_line\", \n",
    "    \"with_span: True\", \n",
    "    \"with_span: False\", \n",
    "    \"include_equation: True\", \n",
    "    \"include_equation: False\", \n",
    "    \"include_background: True\", \n",
    "    \"include_background: False\", \n",
    "    \"table_layout: vertical\", \n",
    "    \"table_layout: horizontal\"\n",
    "] if col in df4.columns]]\n",
    "\n",
    "# selected_columns.to_csv('./table_attribute.csv')\n",
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text Recognition\n",
    "# 文本识别属性统计（单模型/方法）\n",
    "# 针对指定 OCR 类型，统计不同文本属性下的编辑距离表现，并可导出为 CSV。\n",
    "\n",
    "# ocr_types = ['OmniDocBench_easyocr_text_ocr', 'OmniDocBench_openocr_text_ocr']\n",
    "ocr_types = ['drawings_text_ocr']\n",
    "offical_names = ocr_types\n",
    "\n",
    "result_folder = '../result'\n",
    "\n",
    "dict_list = []\n",
    "\n",
    "for ocr_type in ocr_types:\n",
    "    result_path = os.path.join(result_folder, f'{ocr_type}_metric_result.json')\n",
    "    \n",
    "    with open(result_path, 'r') as f:\n",
    "        result = json.load(f)\n",
    "    \n",
    "    # for category_type in result.keys():\n",
    "    dict_list.append(result[\"group\"][\"Edit_dist\"])\n",
    "\n",
    "df4 = pd.DataFrame(dict_list, index=offical_names)\n",
    "df4 = df4.round(3)\n",
    "\n",
    "selected_columns = df4[[col for col in [\n",
    "    \"text_language: text_english\", \n",
    "    \"text_language: text_simplified_chinese\", \n",
    "    \"text_language: text_en_ch_mixed\", \n",
    "    \"text_background: white\", \n",
    "    \"text_background: single_colored\", \n",
    "    \"text_background: multi_colored\", \n",
    "    \"text_rotate: normal\", \n",
    "    \"text_rotate: rotate90\", \n",
    "    \"text_rotate: rotate270\", \n",
    "    \"text_rotate: horizontal\"\n",
    "] if col in df4.columns]]\n",
    "\n",
    "\n",
    "selected_columns.to_csv('.text_attribute.csv')\n",
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'table'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_37684\\3585752589.py\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# for category_type in result.keys():\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mdict_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'table'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"group\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"TEDS\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mdf4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moffical_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'table'"
     ]
    }
   ],
   "source": [
    "# table Recognition\n",
    "# 单元格9：表格识别属性统计（单模型/方法）\n",
    "# 针对指定 OCR 类型，统计不同表格属性下的 TEDS 指标表现，并可导出为 CSV。\n",
    "\n",
    "ocr_types = ['drawings_table']\n",
    "offical_names = ocr_types\n",
    "\n",
    "result_folder = '../result'\n",
    "\n",
    "dict_list = []\n",
    "\n",
    "for ocr_type in ocr_types:\n",
    "    result_path = os.path.join(result_folder, f'{ocr_type}_metric_result.json')\n",
    "    \n",
    "    with open(result_path, 'r') as f:\n",
    "        result = json.load(f)\n",
    "    \n",
    "    # for category_type in result.keys():\n",
    "    dict_list.append(result['table'][\"group\"][\"TEDS\"])\n",
    "\n",
    "df4 = pd.DataFrame(dict_list, index=offical_names)\n",
    "df4 = df4 * 100\n",
    "df4 = df4.round(1)\n",
    "\n",
    "selected_columns = df4[[col for col in [\n",
    "    \"language: table_en\", \n",
    "    \"language: table_simplified_chinese\", \n",
    "    \"language: table_en_ch_mixed\", \n",
    "    \"line: full_line\", \n",
    "    \"line: less_line\", \n",
    "    \"line: fewer_line\", \n",
    "    \"line: wireless_line\", \n",
    "    \"with_span: True\", \n",
    "    \"with_span: False\", \n",
    "    \"include_equation: True\", \n",
    "    \"include_equation: False\", \n",
    "    \"include_background: True\", \n",
    "    \"include_background: False\", \n",
    "    \"table_layout: vertical\", \n",
    "    \"table_layout: horizontal\"\n",
    "] if col in df4.columns]]\n",
    "\n",
    "# selected_columns.to_csv('./table_attribute.csv')\n",
    "selected_columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnidocbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
